# Multi Agent Reinforcement Learning (MARL)
Alec Engl, Evan Hedding, Nitish Gudapati and Shashvat Jayakrishnan
AA277 - Multi-Robot Control and Distributed Optimization, Stanford University

To start training with the files, run:\
"python "pong_episode_run.py" --whichSide True" for training the right side\
"python "pong_episode_run.py" --whichSide False" for training the left side

The following GIF displays the emergent behaviors as a result of the MARL training with self-play

Jitter (Paddles on the right side)\
<img src="https://github.com/gnitish18/Multi-Robot_Reinforcement_Learning/blob/main/Emergent_Behavior-Gifs/Jitter.gif" width="500" height="350">

Ready Rest (Paddles on the right side)\
<img src="https://github.com/gnitish18/Multi-Robot_Reinforcement_Learning/blob/main/Emergent_Behavior-Gifs/ReadyRest.gif" width="500" height="350">

Slice (Second paddle on the left side)\
<img src="https://github.com/gnitish18/Multi-Robot_Reinforcement_Learning/blob/main/Emergent_Behavior-Gifs/Slice.gif" width="500" height="350">

Corner Chop (First paddle on the right side)\
<img src="https://github.com/gnitish18/Multi-Robot_Reinforcement_Learning/blob/main/Emergent_Behavior-Gifs/CornerChop.gif" width="500" height="350">

Load and Shoot (Paddles on the right side)\
<img src="https://github.com/gnitish18/Multi-Robot_Reinforcement_Learning/blob/main/Emergent_Behavior-Gifs/LoadShoot.gif" width="500" height="350">
